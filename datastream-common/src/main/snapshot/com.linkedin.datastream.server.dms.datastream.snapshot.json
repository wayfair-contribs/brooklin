{
  "models" : [ {
    "type" : "record",
    "name" : "DatastreamSource",
    "namespace" : "com.linkedin.datastream.common",
    "doc" : "Datastream source that connector will use to consume events",
    "fields" : [ {
      "name" : "connectionString",
      "type" : "string",
      "doc" : "Source connection string to consume the data from."
    }, {
      "name" : "partitions",
      "type" : "int",
      "doc" : "Number of partitions in the source."
    } ]
  }, {
    "type" : "enum",
    "name" : "DatastreamStatus",
    "namespace" : "com.linkedin.datastream.common",
    "symbols" : [ "INITIALIZING", "READY", "PAUSED", "DELETING", "STOPPED" ]
  }, {
    "type" : "record",
    "name" : "DatastreamDestination",
    "namespace" : "com.linkedin.datastream.common",
    "doc" : "Datastream destination details that the transport provider will use to send events",
    "fields" : [ {
      "name" : "connectionString",
      "type" : "string",
      "doc" : "Destination connection string to write the data to."
    }, {
      "name" : "partitions",
      "type" : "int",
      "doc" : "Number of partitions in the destination."
    }, {
      "name" : "keySerDe",
      "type" : "string",
      "doc" : "SerDe used to serialize/deserialize the key."
    }, {
      "name" : "payloadSerDe",
      "type" : "string",
      "doc" : "SerDe used to serialize/deserialize the payload."
    }, {
      "name" : "envelopeSerDe",
      "type" : "string",
      "doc" : "SerDe used to serialize/deserialize the envelope."
    } ]
  }, {
    "type" : "record",
    "name" : "Datastream",
    "namespace" : "com.linkedin.datastream.common",
    "doc" : "Data model of Datastream",
    "fields" : [ {
      "name" : "name",
      "type" : "string",
      "doc" : "Name of the Datastream."
    }, {
      "name" : "connectorName",
      "type" : "string",
      "doc" : "Name of the connector to be used for reading the change capture events from the source, e.g. Oracle, Espresso, OracleBootstrap, EspressoBootstrap, Mysql etc.."
    }, {
      "name" : "transportProviderName",
      "type" : "string",
      "doc" : "Name of the transport provider."
    }, {
      "name" : "source",
      "type" : "DatastreamSource",
      "doc" : "Source that connector can use to connect to the data store and consume the data."
    }, {
      "name" : "Status",
      "type" : "DatastreamStatus",
      "doc" : "Status of the datastream",
      "symbolDocs" : {
        "READY" : "Datastream destination is created, datastream is split into tasks and assigned and ready for producing and consumption.",
        "INITIALIZING" : "Datastream is created, but not initialized yet."
      }
    }, {
      "name" : "destination",
      "type" : "DatastreamDestination",
      "doc" : "Datastream destination string that the transport provider will use to send the events",
      "optional" : true
    }, {
      "name" : "metadata",
      "type" : {
        "type" : "map",
        "values" : "string"
      },
      "doc" : "Generic metadata for Datastream (e.g. owner, expiration, etc). Metadata is stored as user defined name/value pair.",
      "optional" : true
    } ]
  }, {
    "type" : "record",
    "name" : "TaskHealth",
    "namespace" : "com.linkedin.datastream.diagnostics",
    "doc" : "Datastream task health",
    "fields" : [ {
      "name" : "name",
      "type" : "string",
      "doc" : "name of the task."
    }, {
      "name" : "datastreams",
      "type" : "string",
      "doc" : "Name of the datastreams associated with the task."
    }, {
      "name" : "partitions",
      "type" : "string",
      "doc" : "Partitions associated with the task."
    }, {
      "name" : "source",
      "type" : "string",
      "doc" : "Source of the datastream."
    }, {
      "name" : "destination",
      "type" : "string",
      "doc" : "Destination of the datastream."
    }, {
      "name" : "statusCode",
      "type" : "string",
      "doc" : "Status code of the datastream task."
    }, {
      "name" : "statusMessage",
      "type" : "string",
      "doc" : "Status message of the datastream task."
    }, {
      "name" : "sourceCheckpoint",
      "type" : "string",
      "doc" : "Source checkpoint."
    } ]
  }, {
    "type" : "record",
    "name" : "ConnectorHealth",
    "namespace" : "com.linkedin.datastream.diagnostics",
    "doc" : "Datastream connector health",
    "fields" : [ {
      "name" : "connectorName",
      "type" : "string",
      "doc" : "name of the connector."
    }, {
      "name" : "strategy",
      "type" : "string",
      "doc" : "Strategy used by the connector."
    }, {
      "name" : "tasks",
      "type" : {
        "type" : "array",
        "items" : "TaskHealth"
      },
      "doc" : "tasks assigned to the connector Instance."
    } ]
  } ],
  "schema" : {
    "name" : "datastream",
    "namespace" : "com.linkedin.datastream.server.dms",
    "path" : "/datastream",
    "schema" : "com.linkedin.datastream.common.Datastream",
    "doc" : "Resources classes are used by rest.li to process corresponding HTTP request.\n Note that rest.li will instantiate an object each time it processes a request.\n So do make it thread-safe when implementing the resources.\n\ngenerated from: com.linkedin.datastream.server.dms.DatastreamResources",
    "collection" : {
      "identifier" : {
        "name" : "datastreamId",
        "type" : "string"
      },
      "supports" : [ "batch_update", "create", "delete", "get", "get_all", "update" ],
      "methods" : [ {
        "method" : "create"
      }, {
        "method" : "get"
      }, {
        "method" : "update"
      }, {
        "method" : "delete"
      }, {
        "method" : "batch_update"
      }, {
        "method" : "get_all"
      } ],
      "finders" : [ {
        "name" : "findGroup",
        "doc" : "Find all the datastreams in the same group as the provided {@code datastreamName}\n This finder method can be invoked via /resources/datastream?q=findDuplicates&datastreamName=name",
        "parameters" : [ {
          "name" : "datastreamName",
          "type" : "string"
        } ]
      } ],
      "entity" : {
        "path" : "/datastream/{datastreamId}",
        "actions" : [ {
          "name" : "movePartitions",
          "doc" : "Move partitions to a particular host\nService Returns: Result HTTP status",
          "parameters" : [ {
            "name" : "partitions",
            "type" : "string",
            "doc" : "partitions that need to move to"
          }, {
            "name" : "targetHost",
            "type" : "string",
            "doc" : "target host to accommodate the partitions"
          }, {
            "name" : "notify",
            "type" : "boolean",
            "default" : "true",
            "doc" : "specify if we should notify the leader to start process the assignment, we can stage the update\n               and batch it later by setting it into false"
          } ]
        }, {
          "name" : "pause",
          "doc" : "Pause a datastream\nService Returns: Result HTTP status",
          "parameters" : [ {
            "name" : "force",
            "type" : "boolean",
            "default" : "false",
            "doc" : "whether or not to pause all datastreams within the given datastream's group"
          } ]
        }, {
          "name" : "pauseSourcePartitions",
          "doc" : "Given datastream and a map representing &lt;source, list of partitions to pause&gt;, pauses the partitions.",
          "parameters" : [ {
            "name" : "sourcePartitions",
            "type" : "{ \"type\" : \"map\", \"values\" : \"string\" }",
            "doc" : "StringMap of format &lt;source, comma separated list of partitions or \"*\"&gt;.\n                         <pre>Example: <\"FooTopic\", \"0,13,2\"> or <\"FooTopic\",\"*\"></pre>"
          } ]
        }, {
          "name" : "resume",
          "doc" : "Resume a datastream\nService Returns: Result HTTP status",
          "parameters" : [ {
            "name" : "force",
            "type" : "boolean",
            "default" : "false",
            "doc" : "whether or not to resume all datastreams within the given datastream's group"
          } ]
        }, {
          "name" : "resumeSourcePartitions",
          "doc" : "Given a datastream and a map representing < source, list of partitions to resume >, resumes the partitions.",
          "parameters" : [ {
            "name" : "sourcePartitions",
            "type" : "{ \"type\" : \"map\", \"values\" : \"string\" }",
            "doc" : "StringMap of format <source, comma separated list of partitions or \"*\">.\n                         Example: <\"FooTopic\", \"0,13,2\"> or <\"FooTopic\",\"*\">"
          } ]
        }, {
          "name" : "stop",
          "doc" : "Stop a datastream\nService Returns: Result HTTP status",
          "parameters" : [ {
            "name" : "force",
            "type" : "boolean",
            "default" : "false",
            "doc" : "whether or not to resume all datastreams within the given datastream's group"
          } ]
        } ],
        "subresources" : [ {
          "name" : "checkpoint",
          "namespace" : "com.linkedin.datastream.server.dms",
          "path" : "/datastream/{datastreamId}/checkpoint",
          "schema" : "com.linkedin.datastream.diagnostics.ConnectorHealth",
          "doc" : "The Restli resource of {@link ConnectorHealth}. Used for collecting datastream checkpoint info\n about a {@link Datastream}.\n\ngenerated from: com.linkedin.datastream.server.dms.DatastreamSourceCheckpointResources",
          "simple" : {
            "supports" : [ "get", "update" ],
            "methods" : [ {
              "method" : "get",
              "doc" : "Get source checkpoints of the parent datastream for each tasks"
            }, {
              "method" : "update",
              "doc" : "Update source checkpoint on a given datastream"
            } ],
            "entity" : {
              "path" : "/datastream/{datastreamId}/checkpoint"
            }
          }
        } ]
      }
    }
  }
}